{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import string\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_interview(url, data):\n",
    "  page = requests.get(url)\n",
    "  soup = BeautifulSoup(page.text, 'html.parser')\n",
    "  section = soup.find(attrs={'style':'padding: 10px;', 'valign':'top'})\n",
    "  event = soup.find('h1').get_text()\n",
    "  date = soup.find('h2').get_text()\n",
    "  items = soup.find_all(\"h3\")\n",
    "  names = [item.get_text() for item in items]\n",
    "  for p in soup.find_all([\"strong\", \"i\", \"h1\", \"h2\", \"h3\", \"br\", \"a\"]):\n",
    "    p.decompose()\n",
    "  paragraphs = section.find_all(string=True)\n",
    "  output = \"\"\n",
    "  for p in paragraphs:\n",
    "    text = p.get_text()\n",
    "    output = output + text\n",
    "  data.append([output, event, date, names])\n",
    "\n",
    "def parse_player(url, data):\n",
    "  page = requests.get(url)\n",
    "  soup = BeautifulSoup(page.text, 'html.parser')\n",
    "  table = soup.find('table', attrs={'width':'100%', 'cellspacing':'0', \n",
    "\t                  'cellpadding':'3', 'border':'0'})\n",
    "  if table is None:\n",
    "    return None\n",
    "  links = table.find_all('a', href=True)\n",
    "  for link in links:\n",
    "    parse_interview(link['href'], data)\n",
    "\n",
    "def parse_letter(url, data):\n",
    "  page = requests.get(url)\n",
    "  soup = BeautifulSoup(page.text, 'html.parser')\n",
    "  table = soup.find('table', attrs={'width':'100%', 'cellspacing':'0', \n",
    "\t                  'cellpadding':'3', 'border':'0'})\n",
    "  if table is None:\n",
    "    return None\n",
    "  links = table.find_all('a', href=True)\n",
    "  for link in tqdm(links):\n",
    "    parse_player(link['href'], data)\n",
    "\n",
    "def parse_sport(url):\n",
    "  page = requests.get(url)\n",
    "  soup = BeautifulSoup(page.text, 'html.parser')\n",
    "  table = soup.find_all('table', attrs={'width':'100%', 'cellspacing':'0', \n",
    "\t                  'cellpadding':'5', 'border':'0'})[0]\n",
    "  links = table.find_all('a', href=True)\n",
    "  data = []\n",
    "  for link in links:\n",
    "    parse_letter(link['href'], data)\n",
    "  return data\n",
    "\n",
    "def scrape():\n",
    "  \n",
    "  data = parse_sport(\"https://www.asapsports.com/showcat.php?id=2\")\n",
    "  df = pd.DataFrame(data, columns=['text', 'event', 'date', 'names'])\n",
    "  df.to_csv(\"corpus_creation/interviews_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [05:32<00:00,  2.12s/it]\n",
      "100%|██████████| 320/320 [12:10<00:00,  2.28s/it]  \n",
      "100%|██████████| 319/319 [12:00<00:00,  2.26s/it]\n",
      "100%|██████████| 195/195 [05:48<00:00,  1.79s/it]\n",
      "100%|██████████| 86/86 [02:36<00:00,  1.82s/it]\n",
      "100%|██████████| 145/145 [05:54<00:00,  2.45s/it]\n",
      "100%|██████████| 245/245 [09:47<00:00,  2.40s/it]\n",
      "100%|██████████| 291/291 [09:25<00:00,  1.94s/it]\n",
      "100%|██████████| 26/26 [00:44<00:00,  1.73s/it]\n",
      "100%|██████████| 107/107 [03:30<00:00,  1.97s/it]\n",
      "100%|██████████| 146/146 [04:24<00:00,  1.81s/it]\n",
      "100%|██████████| 212/212 [08:39<00:00,  2.45s/it]\n",
      "100%|██████████| 430/430 [17:56<00:00,  2.50s/it]  \n",
      "100%|██████████| 83/83 [02:10<00:00,  1.58s/it]\n",
      "100%|██████████| 81/81 [02:59<00:00,  2.21s/it]\n",
      "100%|██████████| 204/204 [07:11<00:00,  2.12s/it]\n",
      "100%|██████████| 11/11 [00:28<00:00,  2.62s/it]\n",
      "100%|██████████| 229/229 [08:39<00:00,  2.27s/it]\n",
      "100%|██████████| 392/392 [14:06<00:00,  2.16s/it]  \n",
      "100%|██████████| 146/146 [06:35<00:00,  2.71s/it]\n",
      "100%|██████████| 17/17 [00:24<00:00,  1.46s/it]\n",
      "100%|██████████| 64/64 [03:03<00:00,  2.87s/it]\n",
      "100%|██████████| 224/224 [07:41<00:00,  2.06s/it]\n",
      "100%|██████████| 33/33 [01:17<00:00,  2.36s/it]\n",
      "100%|██████████| 17/17 [00:29<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
