{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "125af9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "\n",
    "# An ASAP Sports Page for a sport is organized in this manner:\n",
    "# Each letter of the alphabet -> Each player with surname beginning with that letter ->\n",
    "# Each interview in which that player appeared.\n",
    "\n",
    "# get the raw text from the interview page. Additionally, get the event, date, and all names\n",
    "# involved in that interview and return a row of our eventual dataframe\n",
    "def parse_interview(url, data):\n",
    "  page = requests.get(url)\n",
    "  soup = BeautifulSoup(page.text, 'html.parser')\n",
    "  section = soup.find(attrs={'style':'padding: 10px;', 'valign':'top'})\n",
    "  event = soup.find('h1').get_text()\n",
    "  date = soup.find('h2').get_text()\n",
    "  items = soup.find_all(\"h3\")\n",
    "  names = [item.get_text() for item in items]\n",
    "  for p in soup.find_all([\"strong\", \"i\", \"h1\", \"h2\", \"h3\", \"br\", \"a\"]):\n",
    "    p.decompose()\n",
    "  paragraphs = section.find_all(string=True)\n",
    "  output = \"\"\n",
    "  for p in paragraphs:\n",
    "    text = p.get_text()\n",
    "    output = output + text\n",
    "  data.append([output, event, date, names])\n",
    "\n",
    "# get link for each interview on the player page and run parse_interview on each\n",
    "def parse_player(url, data):\n",
    "  page = requests.get(url)\n",
    "  soup = BeautifulSoup(page.text, 'html.parser')\n",
    "  table = soup.find('table', attrs={'width':'100%', 'cellspacing':'0', \n",
    "\t                  'cellpadding':'3', 'border':'0'})\n",
    "  if table is None:\n",
    "    return None\n",
    "  links = table.find_all('a', href=True)\n",
    "  for link in links:\n",
    "    parse_interview(link['href'], data)\n",
    "\n",
    "# get link for each player on the letter page and run parse_player on each\n",
    "def parse_letter(url, data):\n",
    "  page = requests.get(url)\n",
    "  soup = BeautifulSoup(page.text, 'html.parser')\n",
    "  table = soup.find('table', attrs={'width':'100%', 'cellspacing':'0', \n",
    "\t                  'cellpadding':'3', 'border':'0'})\n",
    "  if table is None:\n",
    "    return None\n",
    "  links = table.find_all('a', href=True)\n",
    "  for link in tqdm(links):\n",
    "    parse_player(link['href'], data)\n",
    "\n",
    "# get link for each letter of the alphabet on the sport page and run parse_letter on each\n",
    "def parse_sport(url):\n",
    "  page = requests.get(url)\n",
    "  soup = BeautifulSoup(page.text, 'html.parser')\n",
    "  table = soup.find_all('table', attrs={'width':'100%', 'cellspacing':'0', \n",
    "\t                  'cellpadding':'5', 'border':'0'})[0]\n",
    "  links = table.find_all('a', href=True)\n",
    "  data = []\n",
    "  for link in links:\n",
    "    parse_letter(link['href'], data)\n",
    "  return data\n",
    "\n",
    "# assembles raw interview data\n",
    "def scrape(weblink, rewrite=False):\n",
    "  file = Path(\"corpus_creation/summaries.csv\")\n",
    "  if not file.is_file() or rewrite:\n",
    "    # make the summaries csv\n",
    "    data = parse_sport(weblink)\n",
    "    df = pd.DataFrame(data, columns=['text', 'event', 'date', 'names'])\n",
    "    df.to_csv(\"corpus_creation/interviews_raw.csv\", index=False)\n",
    "    return df\n",
    "  df = pd.read_csv(\"corpus_creation/interviews_raw.csv\", converters={'names': pd.eval})\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05af15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "# splits an interview into blocks of question-answer pairs\n",
    "def chunk(row):\n",
    "  text = row.iloc[0]\n",
    "  text = re.sub(r\"â€™\", \"\\'\", text)\n",
    "  text = re.sub(r\"Â\", \"\", text)\n",
    "  text = re.sub(r\"Q\\.\", \"999PLACEHOLDER999 Q.\", text) # rather crude way of making the questions and answers easier to split\n",
    "  QnA = re.split(r\"999PLACEHOLDER999\", text)[1:] # blocks of Questions and Answers\n",
    "  return QnA\n",
    "\n",
    "# helper function to fix OCR errors for and standardize interviewee names.\n",
    "def find_name(interviewee, names):\n",
    "  interviewee_lower = interviewee.lower()\n",
    "  closest_name = None\n",
    "  min = 10000\n",
    "  for name in names:\n",
    "    dist = Levenshtein.distance(interviewee_lower, name.lower())\n",
    "    if dist < min:\n",
    "      min = dist\n",
    "      closest_name = name\n",
    "  return closest_name\n",
    "\n",
    "# helper function to separate the questions and answers,\n",
    "# such that each row has columns of questions, answers, event, date, and interviewee name\n",
    "# as well as the player nationality.\n",
    "\n",
    "def separate(row, nationalities_dict):\n",
    "  interview = row.iloc[0]\n",
    "  event = row.iloc[1]\n",
    "  date = row.iloc[2]\n",
    "  names = row.iloc[3]\n",
    "  output = []\n",
    "  for text in interview: # for each question and its following response(s)\n",
    "    q_and_a = re.split(r\"\\n(?=[A-ZÀ-Ÿ ,.-]+:)\", text)\n",
    "    question = re.sub(r\"Q\\.\", \"\", q_and_a[0]).strip()\n",
    "    for answer in q_and_a[1:]: # go through the responses in case there are multiple responders\n",
    "      interviewee = re.search(r\"([A-ZÀ-Ÿ ,.-]+)(:)\", answer)\n",
    "      # use levenshtein distance to standardize the names\n",
    "      name = find_name(interviewee.group(1), names)\n",
    "      nationality = nationalities_dict[name] # use the nationality dict to get the player nationality\n",
    "      answer_noname = re.sub(interviewee.group(0), \"\", answer).strip()\n",
    "      output.append([question, answer_noname, event, date, name, nationality])\n",
    "  return output\n",
    "\n",
    "# filter out non-MLB events\n",
    "# as well as events centering on non-players, e.g. Winter Meetings, in which\n",
    "# franchise owners and the MLB commissioner are asked much of the questions\n",
    "def filter(data):\n",
    "  raw_data = data.drop_duplicates(subset='text')\n",
    "\n",
    "  mlb_data = raw_data[raw_data['event'].str.contains(\"MLB |NL |AL |WORLD SERIES|HOME RUN CHASE|MEDIA CONFERENCE\", case=False, regex=True)]\n",
    "  to_drop = mlb_data[mlb_data['event'].str.contains(\"NCAA|UNIVERSITY|COLLEGE|COLLEGIATE|STATE|MUNDIAL|ATLANTIC COAST|WINTER MEETINGS\")].index\n",
    "  mlb_data = mlb_data.drop(to_drop)\n",
    "  return mlb_data\n",
    "\n",
    "# return the unique events in the data\n",
    "def get_events(data, rewrite=False):\n",
    "  file = Path(\"corpus_creation/events.csv\")\n",
    "  if not file.is_file() or rewrite:\n",
    "    events = pd.Series(pd.unique(data['event']))\n",
    "    events.to_csv(\"corpus_creation/events.csv\", header=False, index=False)\n",
    "    return events\n",
    "  events = pd.read_csv(\"corpus_creation/events.csv\", header=None)\n",
    "  return events[0]\n",
    "\n",
    "# return the unique names in the data\n",
    "def get_names(data, rewrite=False):\n",
    "  file = Path(\"corpus_creation/interviewee_names.csv\")\n",
    "  if not file.is_file() or rewrite:\n",
    "    names = pd.Series(data['names'].explode().unique())\n",
    "    names.to_csv(\"corpus_creation/interviewee_names.csv\", header=False, index=False)\n",
    "    return names\n",
    "  names = pd.read_csv(\"corpus_creation/interviewee_names.csv\", header=None)\n",
    "  return names[0]\n",
    "\n",
    "# applies the entire process of filtering, cleaning, and splitting the raw data\n",
    "def process(data, nationalities_dict):\n",
    "  data['text'] = data.apply(chunk, axis=1)\n",
    "  chunked = data[data['text'].map(len) > 0]\n",
    "\n",
    "  separated = chunked.apply(separate, args=(nationalities_dict,), axis=1)\n",
    "  separated_flattened = [x for xs in separated for x in xs]\n",
    "  \n",
    "  df = pd.DataFrame(separated_flattened, columns=['question', 'answer', 'event', 'date', 'name', 'nationality'])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65e0b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "# using the nationality_info.csv file, make a dictionary of adjectivals (e.g. Mexican, Japanese)\n",
    "# mapped to country (e.g. Mexico, Japan)\n",
    "def get_nat_info():\n",
    "  nat_df = pd.read_csv(\"corpus_creation/nationality_info.csv\") # need this file\n",
    "  countries = nat_df.iloc[:,0].str.strip()\n",
    "  adjectivals = nat_df.iloc[:,1].str.strip()\n",
    "  nat_info = dict(zip(adjectivals, countries)) # maps the adjectival to the country\n",
    "  return adjectivals, nat_info\n",
    "\n",
    "# use wikipedia API to find the summary for a player.\n",
    "# if the word \"baseball\" does not appear in the summary for a player,\n",
    "# we assume that player is not an MLB player and should therefore be excluded.\n",
    "def find_summary(name):\n",
    "  name = re.sub(r\"[\\\"\\',]\", \"\", name)\n",
    "  results = wikipedia.search(name)\n",
    "  for page in results:\n",
    "    try:\n",
    "      summary = wikipedia.summary(title=page, auto_suggest=False)\n",
    "      if \"baseball\" in summary.lower():\n",
    "        return summary\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "      continue\n",
    "  print(f\"\\\"baseball\\\" not found in any summary for {name}\")\n",
    "  return \"None\"\n",
    "\n",
    "# gets summaries for each player\n",
    "def get_summaries(names):\n",
    "  sums = []\n",
    "  for name in names:\n",
    "    sums.append([name, find_summary(name)])\n",
    "  sums_df = pd.DataFrame(sums, columns=[\"name\", \"summary\"], dtype=str)\n",
    "  return sums_df\n",
    "\n",
    "# returns dictionary mapping the player name to the wikipedia summary\n",
    "def make_summaries(names, rewrite=False):\n",
    "  file = Path(\"corpus_creation/summaries.csv\")\n",
    "  if not file.is_file() or rewrite:\n",
    "    # make the summaries csv\n",
    "    summaries = get_summaries(names)\n",
    "    summaries.to_csv(\"corpus_creation/summaries.csv\", index=False)\n",
    "\n",
    "  summaries = pd.read_csv(\"corpus_creation/summaries.csv\")\n",
    "\n",
    "  summaries_dict = dict(zip(summaries['name'], summaries['summary']))\n",
    "  return summaries_dict\n",
    "\n",
    "# uses summary dictionary, which usually contains the nationality for the player\n",
    "# at a very predictable position of the summary.\n",
    "# returns the determined nationality of the player.\n",
    "def nationality(name, dict, adjectivals, nat_info):\n",
    "  summary = dict[name]\n",
    "  if not isinstance(summary, str):\n",
    "    return None\n",
    "  pattern = '(?:% s)' % '|'.join(adjectivals)\n",
    "\n",
    "  # print(f\"name: {name}\\nsummary:{summary}\\n\")\n",
    "\n",
    "  pos = summary.find(\")\")\n",
    "  match = re.search(pattern, summary[pos:])\n",
    "  if match is None:\n",
    "    # print(f\"nationality not found for {name}.\\nSummary: {summary}\")\n",
    "    return None\n",
    "  return nat_info[match.group(0)]\n",
    "\n",
    "# assembles and returns the dictionary mapping player name to player nationality.\n",
    "def get_nat_dict(names, summaries_dict, rewrite=False):\n",
    "  file = Path(\"corpus_creation/player_nationalities.csv\")\n",
    "  if not file.is_file() or rewrite:\n",
    "    adjectivals, nat_info = get_nat_info()\n",
    "    nationalities = names.apply(nationality, args=(summaries_dict, adjectivals, nat_info))\n",
    "    df = pd.DataFrame({'name'        : names,\n",
    "                       'nationality' : nationalities})\n",
    "    df.to_csv(\"corpus_creation/player_nationalities.csv\", index=False)\n",
    "    nationalities_dict = dict(zip(names, nationalities))\n",
    "    return nationalities_dict\n",
    "  \n",
    "  player_nats = pd.read_csv(\"corpus_creation/player_nationalities.csv\")\n",
    "  players = player_nats.iloc[:,0].str.strip()\n",
    "  nationalities = player_nats.iloc[:,1].str.strip()\n",
    "  nationalities_dict = dict(zip(players, nationalities))\n",
    "\n",
    "  return nationalities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28e1bea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>event</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From 2019, you guys had multiple games where y...</td>\n",
       "      <td>I think very similar to what we were thinking ...</td>\n",
       "      <td>AL WILD CARD SERIES: BLUE JAYS VS TWINS</td>\n",
       "      <td>October 4, 2023</td>\n",
       "      <td>Michael A. Taylor</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When you came in here, you kind of had the exp...</td>\n",
       "      <td>It's tough.  I see the work that he puts in to...</td>\n",
       "      <td>AL WILD CARD SERIES: BLUE JAYS VS TWINS</td>\n",
       "      <td>October 4, 2023</td>\n",
       "      <td>Michael A. Taylor</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We were discussing about how, when you make a ...</td>\n",
       "      <td>I'm just looking to make the play, and I want ...</td>\n",
       "      <td>AL WILD CARD SERIES: BLUE JAYS VS TWINS</td>\n",
       "      <td>October 4, 2023</td>\n",
       "      <td>Michael A. Taylor</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It seems like kind of a curse, is it?</td>\n",
       "      <td>It is.  I get excited.  I'm happy to make the ...</td>\n",
       "      <td>AL WILD CARD SERIES: BLUE JAYS VS TWINS</td>\n",
       "      <td>October 4, 2023</td>\n",
       "      <td>Michael A. Taylor</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When you did get traded over, (indiscernible) ...</td>\n",
       "      <td>I really didn't know what to expect.  I knew t...</td>\n",
       "      <td>AL WILD CARD SERIES: BLUE JAYS VS TWINS</td>\n",
       "      <td>October 4, 2023</td>\n",
       "      <td>Michael A. Taylor</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77744</th>\n",
       "      <td>A lot has been made all year of how flexible t...</td>\n",
       "      <td>Yeah, using guys in different leverage situati...</td>\n",
       "      <td>AL DIVISION SERIES: RAYS VS RED SOX</td>\n",
       "      <td>October 11, 2021</td>\n",
       "      <td>Mike Zunino</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77745</th>\n",
       "      <td>After catching 13 innings, is there any though...</td>\n",
       "      <td>Yeah, there will be plenty of time to rest in ...</td>\n",
       "      <td>AL DIVISION SERIES: RAYS VS RED SOX</td>\n",
       "      <td>October 11, 2021</td>\n",
       "      <td>Mike Zunino</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77746</th>\n",
       "      <td>I know you spoke of how good of a team Boston ...</td>\n",
       "      <td>Yeah, it just sort of speaks about the game of...</td>\n",
       "      <td>AL DIVISION SERIES: RAYS VS RED SOX</td>\n",
       "      <td>October 11, 2021</td>\n",
       "      <td>Mike Zunino</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77747</th>\n",
       "      <td>Schwarber playing with the crowd last night.  ...</td>\n",
       "      <td>Yeah, I think it shows that the atmosphere the...</td>\n",
       "      <td>AL DIVISION SERIES: RAYS VS RED SOX</td>\n",
       "      <td>October 11, 2021</td>\n",
       "      <td>Mike Zunino</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77748</th>\n",
       "      <td>Does experience allow you to do that even more...</td>\n",
       "      <td>I'm sure it does.  It's one of those things wh...</td>\n",
       "      <td>AL DIVISION SERIES: RAYS VS RED SOX</td>\n",
       "      <td>October 11, 2021</td>\n",
       "      <td>Mike Zunino</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76978 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      From 2019, you guys had multiple games where y...   \n",
       "1      When you came in here, you kind of had the exp...   \n",
       "2      We were discussing about how, when you make a ...   \n",
       "3                  It seems like kind of a curse, is it?   \n",
       "4      When you did get traded over, (indiscernible) ...   \n",
       "...                                                  ...   \n",
       "77744  A lot has been made all year of how flexible t...   \n",
       "77745  After catching 13 innings, is there any though...   \n",
       "77746  I know you spoke of how good of a team Boston ...   \n",
       "77747  Schwarber playing with the crowd last night.  ...   \n",
       "77748  Does experience allow you to do that even more...   \n",
       "\n",
       "                                                  answer  \\\n",
       "0      I think very similar to what we were thinking ...   \n",
       "1      It's tough.  I see the work that he puts in to...   \n",
       "2      I'm just looking to make the play, and I want ...   \n",
       "3      It is.  I get excited.  I'm happy to make the ...   \n",
       "4      I really didn't know what to expect.  I knew t...   \n",
       "...                                                  ...   \n",
       "77744  Yeah, using guys in different leverage situati...   \n",
       "77745  Yeah, there will be plenty of time to rest in ...   \n",
       "77746  Yeah, it just sort of speaks about the game of...   \n",
       "77747  Yeah, I think it shows that the atmosphere the...   \n",
       "77748  I'm sure it does.  It's one of those things wh...   \n",
       "\n",
       "                                         event              date  \\\n",
       "0      AL WILD CARD SERIES: BLUE JAYS VS TWINS   October 4, 2023   \n",
       "1      AL WILD CARD SERIES: BLUE JAYS VS TWINS   October 4, 2023   \n",
       "2      AL WILD CARD SERIES: BLUE JAYS VS TWINS   October 4, 2023   \n",
       "3      AL WILD CARD SERIES: BLUE JAYS VS TWINS   October 4, 2023   \n",
       "4      AL WILD CARD SERIES: BLUE JAYS VS TWINS   October 4, 2023   \n",
       "...                                        ...               ...   \n",
       "77744      AL DIVISION SERIES: RAYS VS RED SOX  October 11, 2021   \n",
       "77745      AL DIVISION SERIES: RAYS VS RED SOX  October 11, 2021   \n",
       "77746      AL DIVISION SERIES: RAYS VS RED SOX  October 11, 2021   \n",
       "77747      AL DIVISION SERIES: RAYS VS RED SOX  October 11, 2021   \n",
       "77748      AL DIVISION SERIES: RAYS VS RED SOX  October 11, 2021   \n",
       "\n",
       "                    name    nationality  \n",
       "0      Michael A. Taylor  United States  \n",
       "1      Michael A. Taylor  United States  \n",
       "2      Michael A. Taylor  United States  \n",
       "3      Michael A. Taylor  United States  \n",
       "4      Michael A. Taylor  United States  \n",
       "...                  ...            ...  \n",
       "77744        Mike Zunino  United States  \n",
       "77745        Mike Zunino  United States  \n",
       "77746        Mike Zunino  United States  \n",
       "77747        Mike Zunino  United States  \n",
       "77748        Mike Zunino  United States  \n",
       "\n",
       "[76978 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rewrite flag decides whether to rewrite the csv or not\n",
    "# flipping this flag to True will make the code take a long time,\n",
    "# making the data from scratch.\n",
    "rw_flag = False\n",
    "\n",
    "# putting it all together\n",
    "weblink = \"https://www.asapsports.com/showcat.php?id=2\"\n",
    "raw_data = scrape(weblink, rewrite=rw_flag)\n",
    "mlb_data = filter(raw_data)\n",
    "\n",
    "events = get_events(mlb_data, rewrite=rw_flag)\n",
    "names = get_names(mlb_data, rewrite=rw_flag)\n",
    "\n",
    "summaries_dict = make_summaries(names, rewrite=rw_flag)\n",
    "nationalities_dict = get_nat_dict(names, summaries_dict, rewrite=rw_flag)\n",
    "\n",
    "processed_mlb_data = process(mlb_data, nationalities_dict).dropna()\n",
    "processed_mlb_data.to_csv(\"data/sportsQnA.csv\", index=False)\n",
    "display(processed_mlb_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
